{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#creating all imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a header file to \n",
    "header = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36'} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining All hyperlinks for the different shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new empty list to store all hyperlinks\n",
    "all_hyperlink = []\n",
    "\n",
    "# create a function to get all show links with parameters of the url and header\n",
    "def get_hyperlinks(url, header):\n",
    "    response_soup = requests.get(url, headers = header)\n",
    "    soup = BeautifulSoup(response_soup.text, 'html.parser')\n",
    "\n",
    "    # game tablle is the block of information for all of the shows\n",
    "    shows_table = soup.find_all('div', {'class': 'di-ib clearfix'})\n",
    "    \n",
    "    # game is the box of data that has individual shows in the show_table\n",
    "    for show in shows_table:\n",
    "        \n",
    "        # create a new variable to loop through to obtain the hyperlink in each block\n",
    "        show_links_html = show.find_all('a', href=True)\n",
    "        \n",
    "        # it continues onto this whether it goes into the if statement or not\n",
    "        # will look through each block in show_links_html and appends\n",
    "        # that hyperlink into my list of all hyperlinks\n",
    "        for show_link in show_links_html:\n",
    "            if 'video' not in show_link['href']:\n",
    "                all_hyperlink.append(show_link['href']+'/reviews')\n",
    "                \n",
    "               # print(game_link['href'])\n",
    "            \n",
    "    return all_hyperlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterating through 1000 shows to obtain the hyperlink for each show\n",
    "# limit is the starting number for the animes, so i initilize i as 0 and adds 50 each time \n",
    "\n",
    "i = 0\n",
    "while i <= 1000:\n",
    "    url = 'https://myanimelist.net/topanime.php?type=tv&limit={}'.format(i)        \n",
    "    get_hyperlinks(url, header)\n",
    "    i += 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterating through all the different shows to get each page of their reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an empty list to store all the review pages for each show\n",
    "all_review_hyperlinks = []\n",
    "\n",
    "\n",
    "# goes through each page of the reviews from 1 - 10 and stores that page of reviews to a\n",
    "# list to iterate through later on\n",
    "\n",
    "for link in all_hyperlink:\n",
    "    for i in range(1, 16):\n",
    "        all_review_hyperlinks.append(link+'?p={}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dictionaries each review with the title of the show, reviewer, review and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing time to give the loop some time to rest not to create issues when pulling data from website\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty list of show_reviews\n",
    "show_review_list = []\n",
    "\n",
    "# function to get each review, reviewer and score and save it in a dictionary along with the\n",
    "# title of the game\n",
    "def each_review(url):\n",
    "    \n",
    "    # sleeping for 2 seconds \n",
    "    time.sleep(2)\n",
    "    \n",
    "# getting the beautiful soup parser initialized, changes as the url changes which will be \n",
    "# looped in the next block\n",
    "    response_soup = requests.get(url, headers = header)\n",
    "    soup = BeautifulSoup(response_soup.text, 'html.parser')\n",
    "    \n",
    "# try and except for each page to make sure the page exists and it does not go straight to\n",
    "# a 404 error page, if it does then it will skip that page and move onto the next one\n",
    "    try:\n",
    "\n",
    "#grabs the title of the game at the top of each page\n",
    "        try: \n",
    "            title = soup.find('span', {'itemprop': 'name'})('span')[0].text\n",
    "        \n",
    "        except (TypeError, IndexError):\n",
    "            try: \n",
    "                title = soup.find('span', {'itemprop': 'name'}).text\n",
    "                \n",
    "            except AttributeError:\n",
    "                pass\n",
    "            pass\n",
    "# this grabs the entire block of reviews on the page, used to loop through to grab individual\n",
    "# reviews and scores\n",
    "        user_reviews_list = soup.find_all('div', {'class' : 'borderDark'})\n",
    "    except AttributeError:\n",
    "            pass\n",
    "    \n",
    "    try:\n",
    "        \n",
    "#looping through the reviews in the block to get the user, review and score\n",
    "        for x in user_reviews_list:\n",
    "            try:\n",
    "                user = x.find('div', {'style': 'float: left;'})('a')[1].text\n",
    "                user_score = int((x.find('div', {'class': 'mb8'})('div')[2].text).split()[-1])\n",
    "                user_reviews = x.find('div', {'class': 'spaceit textReadability word-break pt8 mt8'}).text\n",
    "\n",
    "# Storing the title, user, user score and review in each iteration in a dictionary that is \n",
    "# overwritten at every new iteration\n",
    "                show_review_dict = {\n",
    "                    'title': title,\n",
    "                    'user' : user,\n",
    "                    'user_score': user_score,\n",
    "                    'user_review' : user_reviews\n",
    "                }\n",
    "\n",
    "# stores the dictionary in a list each iteration                \n",
    "                show_review_list.append(show_review_dict)\n",
    "            except AttributeError:\n",
    "                pass\n",
    "            \n",
    "    except UnboundLocalError:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    return show_review_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the function constantly changing the url using the list of hyperlinks\n",
    "# created earlier\n",
    "\n",
    "for link in all_review_hyperlinks:\n",
    "    url = link\n",
    "    each_review(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the list of dictionaries into a dataframe\n",
    "\n",
    "df = pd.DataFrame(show_review_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the dataframe as a csv file\n",
    "\n",
    "df.to_csv('anime_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
